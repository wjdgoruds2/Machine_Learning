{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMF5e/eHaVpKHS1zBYpIy3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjdgoruds2/Machine_Learning/blob/main/State_action_value_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnzxfKNPYaGc",
        "outputId": "3b4b557c-e27a-4391-bbf9-3c67b333d9ef"
      },
      "source": [
        "import numpy as np#벡터와 행렬 연산\n",
        "import matplotlib.pyplot as plt#그래프 시각화 위함\n",
        "import time#시간 다루기\n",
        "\n",
        "class Environment:\n",
        "  cliff=-3;road=-1;sink=-2;goal=2#절벽,길,목적지,보상 설정\n",
        "  goal_position=[2,3]#목표 위치 설정\n",
        "  reward_list=[[road,road,road,road],[road,road,sink,road],[road,road,road,goal]]#보상 리스트 숫자 설정\n",
        "  reward_list1=[['road','road','road','road'],['road','road','sink','road'],['road','road','road','goal']]#보상 리스트 문자 설정\n",
        "\n",
        "  def __init__(self):#보상값 생성자\n",
        "    self.reward=np.asarray(self.reward_list)#보상 리스트를 배열로 설정\n",
        "\n",
        "  def move(self,agent,action):#선택된 에이전트의 행동 결과 반환 (미로밖일 경우 이전 좌표로 다시 복귀)\n",
        "    done=False\n",
        "    new_pos=agent.pos+agent.action[action]#현재 위치+행동값->새로운 위치값\n",
        "\n",
        "    if self.reward_list1[agent.pos[0]][agent.pos[1]]=='goal':#현재좌표가 목적지 인지확인\n",
        "      reward=self.goal#목적지 보상값\n",
        "      observation=agent.set_pos(agent.pos)#에이전트 위치 저장\n",
        "      done=True\n",
        "    elif new_pos[0] < 0 or new_pos[0]>=self.reward.shape[0] or new_pos[1]<0 or new_pos[1] >= self.reward.shape[1]:#이동 후 좌표가 미로 밖인 확인\n",
        "      reward=self.cliff#절벽 보상값\n",
        "      observation=agent.set_pos(agent.pos)#에이전트 위치 저장\n",
        "      done=True\n",
        "    else:#이동 후 좌표가 길이라면\n",
        "      observation=agent.set_pos(new_pos)#에이전트 위치 저장\n",
        "      reward=self.reward[observation[0],observation[1]]\n",
        "    return observation,reward,done\n",
        "\n",
        "class Agent:\n",
        "  action=np.array([[-1,0],[0,1],[1,0],[0,-1]])#행동에 따른 에이전트의 좌표 이동(위, 오른쪽, 아래, 왼쪽)\n",
        "  select_action_pr=np.array([0.25,0.25,0.25,0.25])# 각 행동별 선택확률\n",
        "\n",
        "  def __init__(self,initial_position):#에이전트 초기 위치 저장\n",
        "    self.pos=initial_position\n",
        "\n",
        "  def set_pos(self,position):#에이전트 위치 저장\n",
        "    self.pos=position\n",
        "    return self.pos\n",
        "  \n",
        "  def get_pos(self):#에이전트 위치 불러오기\n",
        "    return self.pos\n",
        "\n",
        "def action_value_function(env,agent,act,G,max_step,now_step):\n",
        "  gamma=0.9#감가율 설정\n",
        "\n",
        "  if env.reward_list1[agent.pos[0]][agent.pos[1]] == 'goal':#현재 위치가 목적지인지 확인\n",
        "    return env.goal\n",
        "  if max_step==now_step:#마지막 상태는 보상만 계산\n",
        "    observation,reward,done=env.move(agent,act)\n",
        "    G+=agent.select_action_pr[act]*reward\n",
        "    return G\n",
        "  else:#현재 상태의 보상을 계산한 후 다음 행동과 함께 다음 step으로 이동\n",
        "    pos1=agent.get_pos()#현재 위치 저장\n",
        "    observation,reward,done=env.move(agent,act)\n",
        "    G+=agent.select_action_pr[act]*reward\n",
        "    \n",
        "    if done==True:#이동 후 위치 확인 : 미로밖, 벽, 구멍인 경우 이동전 좌표로 다시 이동\n",
        "      if observation[0]<0 or observation[0]>=env.reward.shape[0] or observation[1]<0 or observation[1]>=env.reward.shape[1]:\n",
        "        agent.set_pos(pos1)\n",
        "\n",
        "    pos1=agent.get_pos()#현재 위치를 다시 저장\n",
        "\n",
        "    for i in range(len(agent.action)):#현재 위치에서 가능한 모든 행동을 선택한 후 이동\n",
        "      agent.set_pos(pos1)\n",
        "      next_v=action_value_function(env,agent,i,0,max_step,now_step+1)\n",
        "      G+=agent.select_action_pr[i]*gamma*next_v\n",
        "    return G\n",
        "\n",
        "def show_q_table(q_table,env):# Q table 그리기\n",
        "  for i in range(env.reward.shape[0]):\n",
        "    print('+-----------------------'*env.reward.shape[1],end='');print('+')\n",
        "    for k in range(3):\n",
        "      print('|',end='')\n",
        "      for j in range(env.reward.shape[1]):\n",
        "        if k==0:\n",
        "          print('{0:10.2f}   |'.format(q_table[i,j,0]),end='')\n",
        "        if k==1:\n",
        "          print('{0:6.2f}{1:6.2f} |'.format(q_table[i,j,3],q_table[i,j,1]),end='')\n",
        "        if k==2:\n",
        "          print('{0:10.2f}   |'.format(q_table[i,j,2]),end='')\n",
        "      print()\n",
        "  print('+-----------------------'*env.reward.shape[1],end='');print('+')\n",
        "\n",
        "def show_q_table_arrow(q_table,env):# 정책 policy 화살표로 그리기\n",
        "  for i in range(env.reward.shape[0]):\n",
        "    print('+-----------------------'*env.reward.shape[1],end='');print('+')\n",
        "    for k in range(3):\n",
        "      print('|',end='')\n",
        "      for j in range(env.reward.shape[1]):\n",
        "        if k==0:\n",
        "          if np.max(q[i,j,:]) == q[i,j,0]:\n",
        "            print('       ↑      |',end='')\n",
        "          else:\n",
        "            print('               |',end='')\n",
        "        if k==1:\n",
        "            if np.max(q[i,j,:]) == q[i,j,1] and np.max(q[i,j,:])==q[i,j,3]:\n",
        "              print('     ←  →    |',end='')\n",
        "            elif np.max(q[i,j,:]) == q[i,j,1]:\n",
        "              print('        →     |',end='')\n",
        "            elif np.max(q[i,j,:]) == q[i,j,3]:\n",
        "              print('     ←        |',end='')\n",
        "            else:\n",
        "              print('               |',end='') \n",
        "        if k==2:\n",
        "            if np.max(q[i,j,:]) == q[i,j,2]:\n",
        "              print('       ↓      |',end='')\n",
        "            else:\n",
        "              print('               |',end='') \n",
        "      print()\n",
        "  print('+-----------------------'*env.reward.shape[1],end='');print('+')\n",
        "\n",
        "env=Environment()#환경 초기화\n",
        "initial_position=np.array([0,0])#초기값 설정\n",
        "agent=Agent(initial_position)#에이전트 초기화\n",
        "np.random.seed(0)\n",
        "max_step_number=8#현재부터 max_step 까지 계산\n",
        "\n",
        "for max_step in range(max_step_number):#모든 상태에 대해\n",
        "  print('max_step={}'.format(max_step))\n",
        "  q_table=np.zeros((env.reward.shape[0],env.reward.shape[1],len(agent.action)))# 미로 상의 모든 상태에서 가능한 행동의 가치를 저장할 테이블을 정의\n",
        "  for i in range(env.reward.shape[0]):\n",
        "    for j in range(env.reward.shape[1]):\n",
        "      for action in range(len(agent.action)):#모든 행동에 대해\n",
        "        agent.set_pos([i,j])#에이전트의 위치를 초기화\n",
        "        q_table[i,j,action]=action_value_function(env,agent,action,0,max_step,0)#현재 위치에서 행동 가치를 계산\n",
        "  q=np.round(q_table,2)\n",
        "  print('\\nQ-table')\n",
        "  show_q_table(q,env)#Q테이블 출력\n",
        "  print('\\n정책')\n",
        "  show_q_table_arrow(q,env)#화살표 방향 출력\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_step=0\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -0.75   |     -0.75   |     -0.75   |     -0.75   |\n",
            "| -0.75 -0.25 | -0.25 -0.25 | -0.25 -0.25 | -0.25 -0.75 |\n",
            "|     -0.25   |     -0.25   |     -0.50   |     -0.25   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -0.25   |     -0.25   |     -0.25   |     -0.25   |\n",
            "| -0.75 -0.25 | -0.25 -0.50 | -0.25 -0.25 | -0.50 -0.75 |\n",
            "|     -0.25   |     -0.25   |     -0.25   |      0.50   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -0.25   |     -0.25   |     -0.50   |      2.00   |\n",
            "| -0.75 -0.25 | -0.25 -0.25 | -0.25  0.50 |  2.00  2.00 |\n",
            "|     -0.75   |     -0.75   |     -0.75   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |     ←  →    |     ←  →    |     ←        |\n",
            "|       ↓      |       ↓      |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|       ↑      |       ↑      |       ↑      |               |\n",
            "|        →     |     ←        |     ←  →    |               |\n",
            "|       ↓      |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|       ↑      |       ↑      |               |       ↑      |\n",
            "|        →     |     ←  →    |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "max_step=1\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.20   |     -1.09   |     -1.14   |     -1.20   |\n",
            "| -1.20 -0.59 | -0.70 -0.64 | -0.59 -0.70 | -0.64 -1.20 |\n",
            "|     -0.59   |     -0.53   |     -0.73   |     -0.48   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -0.70   |     -0.59   |     -0.64   |     -0.70   |\n",
            "| -1.09 -0.53 | -0.59 -0.73 | -0.53 -0.48 | -0.73 -0.98 |\n",
            "|     -0.70   |     -0.59   |     -0.48   |      2.30   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -0.59   |     -0.53   |     -0.73   |      2.00   |\n",
            "| -1.20 -0.59 | -0.70 -0.48 | -0.59  2.30 |  2.00  2.00 |\n",
            "|     -1.20   |     -1.09   |     -0.98   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |     ←        |               |\n",
            "|       ↓      |       ↓      |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |       ↑      |               |               |\n",
            "|        →     |     ←        |        →     |               |\n",
            "|               |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|       ↑      |               |               |       ↑      |\n",
            "|        →     |        →     |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "max_step=2\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.55   |     -1.42   |     -1.46   |     -1.54   |\n",
            "| -1.55 -0.92 | -1.05 -0.96 | -0.92 -1.04 | -0.96 -1.54 |\n",
            "|     -0.93   |     -0.81   |     -0.98   |     -0.27   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.05   |     -0.92   |     -0.96   |     -1.04   |\n",
            "| -1.43 -0.81 | -0.93 -0.98 | -0.81 -0.27 | -0.98 -0.77 |\n",
            "|     -1.05   |     -0.88   |     -0.25   |      2.30   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -0.93   |     -0.81   |     -0.98   |      2.00   |\n",
            "| -1.55 -0.88 | -1.05 -0.25 | -0.88  2.30 |  2.00  2.00 |\n",
            "|     -1.55   |     -1.38   |     -0.75   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |     ←        |               |\n",
            "|               |       ↓      |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |               |               |\n",
            "|               |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |       ↑      |\n",
            "|        →     |        →     |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "max_step=3\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.86   |     -1.70   |     -1.74   |     -1.72   |\n",
            "| -1.86 -1.20 | -1.36 -1.24 | -1.20 -1.22 | -1.24 -1.72 |\n",
            "|     -1.23   |     -1.08   |     -1.02   |     -0.36   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.36   |     -1.20   |     -1.24   |     -1.22   |\n",
            "| -1.73 -1.08 | -1.23 -1.02 | -1.08 -0.36 | -1.02 -0.86 |\n",
            "|     -1.36   |     -1.04   |     -0.32   |      2.30   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.23   |     -1.08   |     -1.02   |      2.00   |\n",
            "| -1.86 -1.04 | -1.36 -0.32 | -1.04  2.30 |  2.00  2.00 |\n",
            "|     -1.86   |     -1.54   |     -0.82   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |               |               |\n",
            "|               |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |        →     |               |               |\n",
            "|               |               |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |       ↑      |\n",
            "|        →     |        →     |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "max_step=4\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -2.14   |     -1.96   |     -1.92   |     -1.88   |\n",
            "| -2.14 -1.46 | -1.64 -1.42 | -1.46 -1.38 | -1.42 -1.88 |\n",
            "|     -1.49   |     -1.26   |     -1.18   |     -0.43   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.64   |     -1.46   |     -1.42   |     -1.38   |\n",
            "| -1.99 -1.26 | -1.49 -1.18 | -1.26 -0.43 | -1.18 -0.93 |\n",
            "|     -1.59   |     -1.22   |     -0.38   |      2.30   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.49   |     -1.26   |     -1.18   |      2.00   |\n",
            "| -2.09 -1.22 | -1.59 -0.38 | -1.22  2.30 |  2.00  2.00 |\n",
            "|     -2.09   |     -1.72   |     -0.88   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |               |               |\n",
            "|               |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |        →     |               |               |\n",
            "|               |               |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |       ↑      |\n",
            "|        →     |        →     |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "max_step=5\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -2.38   |     -2.16   |     -2.09   |     -2.01   |\n",
            "| -2.38 -1.66 | -1.88 -1.59 | -1.66 -1.51 | -1.59 -2.01 |\n",
            "|     -1.71   |     -1.45   |     -1.28   |     -0.52   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.88   |     -1.66   |     -1.59   |     -1.51   |\n",
            "| -2.21 -1.45 | -1.71 -1.28 | -1.45 -0.52 | -1.28 -1.02 |\n",
            "|     -1.80   |     -1.36   |     -0.47   |      2.30   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.71   |     -1.45   |     -1.28   |      2.00   |\n",
            "| -2.30 -1.36 | -1.80 -0.47 | -1.36  2.30 |  2.00  2.00 |\n",
            "|     -2.30   |     -1.86   |     -0.97   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |               |               |\n",
            "|               |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |        →     |               |               |\n",
            "|               |               |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |       ↑      |\n",
            "|        →     |        →     |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "max_step=6\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -2.58   |     -2.34   |     -2.22   |     -2.13   |\n",
            "| -2.58 -1.84 | -2.08 -1.72 | -1.84 -1.63 | -1.72 -2.13 |\n",
            "|     -1.90   |     -1.60   |     -1.41   |     -0.59   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -2.08   |     -1.84   |     -1.72   |     -1.63   |\n",
            "| -2.40 -1.60 | -1.90 -1.41 | -1.60 -0.59 | -1.41 -1.09 |\n",
            "|     -1.98   |     -1.51   |     -0.55   |      2.30   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -1.90   |     -1.60   |     -1.41   |      2.00   |\n",
            "| -2.48 -1.51 | -1.98 -0.55 | -1.51  2.30 |  2.00  2.00 |\n",
            "|     -2.48   |     -2.01   |     -1.05   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |               |               |\n",
            "|               |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |        →     |               |               |\n",
            "|               |               |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |       ↑      |\n",
            "|        →     |        →     |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "max_step=7\n",
            "\n",
            "Q-table\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -2.75   |     -2.49   |     -2.35   |     -2.23   |\n",
            "| -2.75 -1.99 | -2.25 -1.85 | -1.99 -1.73 | -1.85 -2.23 |\n",
            "|     -2.06   |     -1.75   |     -1.50   |     -0.66   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -2.25   |     -1.99   |     -1.85   |     -1.73   |\n",
            "| -2.56 -1.75 | -2.06 -1.50 | -1.75 -0.66 | -1.50 -1.16 |\n",
            "|     -2.13   |     -1.63   |     -0.62   |      2.30   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|     -2.06   |     -1.75   |     -1.50   |      2.00   |\n",
            "| -2.63 -1.63 | -2.13 -0.62 | -1.63  2.30 |  2.00  2.00 |\n",
            "|     -2.63   |     -2.13   |     -1.12   |      2.00   |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "\n",
            "정책\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |               |               |               |\n",
            "|               |       ↓      |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |               |\n",
            "|        →     |        →     |               |               |\n",
            "|               |               |       ↓      |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n",
            "|               |               |               |       ↑      |\n",
            "|        →     |        →     |        →     |     ←  →    |\n",
            "|               |               |               |       ↓      |\n",
            "+-----------------------+-----------------------+-----------------------+-----------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hBXysI38zhX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}